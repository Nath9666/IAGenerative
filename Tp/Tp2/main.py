import tensorflow as tf 
from tensorflow.keras import layers 
import numpy as np 
import matplotlib.pyplot as plt 
 
# Load MNIST dataset 
(x_train, _), (_, _) = tf.keras.datasets.mnist.load_data() 
x_train = x_train.astype("float32") / 255.0 
x_train = np.expand_dims(x_train, -1) 
 
latent_dim = 100
 
# CNN Generator 
def build_generator(): 
    model = tf.keras.Sequential([ 
        layers.Dense(7 * 7 * 256, input_dim=latent_dim), 
        layers.Reshape((7, 7, 256)), 
        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding="same"), 
        layers.LeakyReLU(alpha=0.2), 
        layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding="same"), 
        layers.LeakyReLU(alpha=0.2), 
        layers.Conv2DTranspose(1, kernel_size=7, activation="sigmoid", padding="same") 
    ]) 
    return model 
 
# CNN Discriminator 
def build_discriminator(): 
    model = tf.keras.Sequential([ 
        layers.Conv2D(64, kernel_size=4, strides=2, padding="same", input_shape=(28, 28, 1)), 
        layers.LeakyReLU(alpha=0.2), 
        layers.Conv2D(128, kernel_size=4, strides=2, padding="same"), 
        layers.LeakyReLU(alpha=0.2), 
        layers.Flatten(), 
        layers.Dense(1, activation="sigmoid") 
    ]) 
    return model 
 
# GAN Model 
generator = build_generator() 
discriminator = build_discriminator() 
discriminator.compile(optimizer=tf.keras.optimizers.Adam(0.0002), 
loss="binary_crossentropy", metrics=["accuracy"]) 
discriminator.trainable = False 
 
gan_input = layers.Input(shape=(latent_dim,)) 
gan_output = discriminator(generator(gan_input)) 
gan = tf.keras.Model(gan_input, gan_output) 
gan.compile(optimizer=tf.keras.optimizers.Adam(0.0002), loss="binary_crossentropy") 
 
# Training the GAN 
def train_gan(generator, discriminator, gan, epochs, batch_size=128): 
    for epoch in range(epochs): 
        for _ in range(batch_size): 
            # Train discriminator 
            noise = tf.random.normal([batch_size, latent_dim]) 
            fake_images = generator.predict(noise) 
            real_images = x_train[np.random.randint(0, x_train.shape[0], batch_size)] 
             
            real_labels = tf.ones((batch_size, 1)) 
            fake_labels = tf.zeros((batch_size, 1)) 
             
            d_loss_real = discriminator.train_on_batch(real_images, real_labels) 
            d_loss_fake = discriminator.train_on_batch(fake_images, fake_labels) 
             
            # Train generator 
            misleading_labels = tf.ones((batch_size, 1)) 
            g_loss = gan.train_on_batch(noise, misleading_labels) 
         
    print(f"Epoch {epoch + 1}/{epochs}, D Loss: {d_loss_real[0] + d_loss_fake[0]}, G Loss: {g_loss}") 
 
train_gan(generator, discriminator, gan, epochs=10) 
 
# Generate and visualize images 
def generate_images(generator, n_images): 
    noise = tf.random.normal([n_images, latent_dim]) 
    generated_images = generator.predict(noise) 
    fig, axes = plt.subplots(1, n_images, figsize=(20, 4)) 
    for i, img in enumerate(generated_images): 
        axes[i].imshow(img.squeeze(), cmap="gray") 
        axes[i].axis("off") 
    plt.show()
    plt.savefig('generated_images.png') 
 
generate_images(generator, 10)